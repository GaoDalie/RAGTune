{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataset"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading dataset-1.6.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n",
      "  Downloading SQLAlchemy-1.4.54-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting alembic>=0.6.2 (from dataset)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting banal>=1.0.1 (from dataset)\n",
      "  Downloading banal-1.0.6-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Mako (from alembic>=0.6.2->dataset)\n",
      "  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\mrtar\\desktop\\fine_tuning_model\\myenv\\lib\\site-packages (from alembic>=0.6.2->dataset) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<2.0.0,>=1.3.2->dataset)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=0.6.2->dataset)\n",
      "  Downloading MarkupSafe-3.0.1-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)\n",
      "Downloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.2 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/233.2 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 61.4/233.2 kB 656.4 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 122.9/233.2 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 153.6/233.2 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 233.2/233.2 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
      "Downloading SQLAlchemy-1.4.54-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.6 MB 1.7 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/1.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/1.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.7/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.2/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.2/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.6 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.4/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.5/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.5/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "   ---------------------------------------- 0.0/298.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 122.9/298.9 kB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 225.3/298.9 kB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 266.2/298.9 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 298.9/298.9 kB 1.7 MB/s eta 0:00:00\n",
      "Using cached Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Downloading MarkupSafe-3.0.1-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Installing collected packages: banal, MarkupSafe, greenlet, sqlalchemy, Mako, alembic, dataset\n",
      "Successfully installed Mako-1.3.5 MarkupSafe-3.0.1 alembic-1.13.3 banal-1.0.6 dataset-1.6.2 greenlet-3.1.1 sqlalchemy-1.4.54\n"
     ]
    }
   ],
   "source": [
    "!pip install dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 101 examples [00:00, 2453.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'question', 'correct_answer'],\n",
      "    num_rows: 101\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": \"dataset_QA.json\",}\n",
    "dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows:\n",
      "Empty DataFrame\n",
      "Columns: [instruction, question, correct_answer]\n",
      "Index: []\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate rows in the dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data_files = {\"train\": \"dataset_QA.json\"}\n",
    "dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "\n",
    "# Convert Hugging Face dataset to a Pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Print duplicate rows (if any)\n",
    "print(\"Duplicate rows:\")\n",
    "print(df[duplicates])\n",
    "\n",
    "# Optionally, print the count of duplicate rows\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"You are a scientist. I will provide a question, and you will respond with the result based on your scientific knowledge. Answer the question using the provided context. If the question cannot be answered with the given information, respond with 'I don't know.\", 'question': 'When a meteoroid reaches earth, what is the remaining object called?', 'correct_answer': 'Meteoroids are smaller than asteroids, ranging from the size of boulders to the size of sand grains. When meteoroids enter Earthâ€™s atmosphere, they vaporize, creating a trail of glowing gas called a meteor. If any of the meteoroid reaches Earth, the remaining object is called a meteorite. Final Answer : meteorite'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
